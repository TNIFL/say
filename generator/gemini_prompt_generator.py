# gemini.py
import os
from typing import Tuple, Dict, Any
from google import genai

from google.genai.types import GenerationConfig


def _extract_usage(resp) -> Dict[str, Any]:
    prompt = completion = total = None
    usage = getattr(resp, "usage", None)
    if usage:
        prompt = getattr(usage, "prompt_token_count", None)
        completion = getattr(usage, "candidates_token_count", None) or getattr(usage, "output_token_count", None)
        total = getattr(usage, "total_token_count", None)
        if hasattr(usage, "get"):
            prompt = prompt or usage.get("prompt_token_count")
            completion = completion or usage.get("candidates_token_count") or usage.get("output_token_count")
            total = total or usage.get("total_token_count")
    if (prompt is None or completion is None or total is None) and hasattr(resp, "to_dict"):
        try:
            d = resp.to_dict()
            u = d.get("usage", {}) if isinstance(d, dict) else {}
            prompt = prompt or u.get("prompt_token_count")
            completion = completion or u.get("candidates_token_count") or u.get("output_token_count")
            total = total or u.get("total_token_count")
        except Exception:
            pass
    return {"prompt_tokens": prompt, "completion_tokens": completion, "total_tokens": total}


def call_gemini(system_prompt, final_user_prompt) -> Tuple[str, Dict[str, Any]]:
    """Google Gemini ëª¨ë¸ë¡œ ë¬¸ì¥ ë‹¤ë“¬ê¸° (DB í† í° ë¡œê¹… í˜¸í™˜ ë°˜í™˜)"""
    print("[Gemini] gemini_generate í˜¸ì¶œë¨")

    # 0) í™˜ê²½ë³€ìˆ˜/ëª¨ë¸ ì ê²€
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        print("[Gemini][ERROR] GEMINI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ë¹„ì–´ ìˆìŒ")
        return "", {"provider": "gemini", "model": None, "prompt_tokens": None, "completion_tokens": None, "total_tokens": None}

    # ì‚¬ìš©ìê°€ ì§€ì •í•œ ëª¨ë¸ì´ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©, ì—†ìœ¼ë©´ ì•ˆì „í•œ ê¸°ë³¸ê°’ìœ¼ë¡œ
    # pro ëª¨ë¸ì´ ê¶Œí•œ/ë¦¬ì „ ë¬¸ì œë¡œ ìì£¼ ì‹¤íŒ¨í•˜ë‹ˆ ê¸°ë³¸ì€ flashë¡œ ë‘ 

    model = "gemini-2.5-pro"
    client = genai.Client(api_key=api_key)

    # 1ì°¨ ì‹œë„: ì§€ì •(ë˜ëŠ” ê¸°ë³¸) ëª¨ë¸
    print("1st ì‹œë„")
    try:
        print(f"[Gemini] model={model}")
        config = GenerationConfig(
            # system_instruction=system_prompt,
            temperature=0.7  # ë‹¤ë¥¸ ì„¤ì •ê°’ë“¤ì€ ìœ ì§€
        )

        # 2. generate_content ë©”ì„œë“œì— system_instructionì„ ì§ì ‘ ì „ë‹¬
        resp = client.models.generate_content(
            system_instruction=system_prompt,  # ğŸ‘ˆ ì—¬ê¸°ì— system_prompt ë¬¸ìì—´ì„ ë„£ìŠµë‹ˆë‹¤.
            model=model,
            contents=[
                {
                    "role": "user",
                    "parts": [{"text": final_user_prompt}]
                }
            ],
            config=config  # ğŸ‘ˆ config ê°ì²´ëŠ” ë‹¤ë¥¸ ì„¤ì •ê°’ë§Œ ì „ë‹¬
        )
        text = (getattr(resp, "text", "") or "").strip()
        print("[Gemini] 1st call OK")
        usage = _extract_usage(resp)
        return text, {
            "provider": "gemini",
            "model": model,
            "prompt_tokens": usage.get("prompt_tokens"),
            "completion_tokens": usage.get("completion_tokens"),
            "total_tokens": usage.get("total_tokens"),
        }
    except Exception as e:
        # ëª¨ë¸ ì´ë¦„ ì˜¤ë¥˜ / ê¶Œí•œ / ë¦¬ì „ ë¬¸ì œ ê°€ëŠ¥ì„± â†’ ì•ˆì „ ëª¨ë¸ë¡œ 1íšŒ í´ë°±
        print("[Gemini][ERROR] 1st call failed:", repr(e))

    # 2ì°¨ í´ë°±: ê°€ì¥ í˜¸í™˜ì„± ì¢‹ì€ í”Œë˜ì‹œ ê³„ì—´
    fallback_model = "gemini-2.0-flash"
    if model != fallback_model:
        try:
            print(f"[Gemini] fallback model={fallback_model}")
            resp = client.models.generate_content(
                contents=final_user_prompt,
                system_instruction=system_prompt
            )
            text = (getattr(resp, "text", "") or "").strip()
            print("[Gemini] fallback OK, text length:", len(text))
            usage = _extract_usage(resp)
            return text, {
                "provider": "gemini",
                "model": fallback_model,
                "prompt_tokens": usage.get("prompt_tokens"),
                "completion_tokens": usage.get("completion_tokens"),
                "total_tokens": usage.get("total_tokens"),
            }
        except Exception as e2:
            print("[Gemini][ERROR] fallback failed:", repr(e2))

    # ìµœì¢… ì‹¤íŒ¨
    return "", {
        "provider": "gemini",
        "model": model,
        "prompt_tokens": None,
        "completion_tokens": None,
        "total_tokens": None,
    }
